# -*- coding: utf-8 -*-
"""Titanic_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LXwgSShqnvM7UE-moHd4_o_HRXCkSjzB

#TITANIC PROJECT
"""

# import file ke google colab
from google.colab import files

# upload file
files.upload()

# import modul yang dibutuhkan
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# baca data yang telah diupload
train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")

"""# DATA UNDERSTANDING TRAIN"""

# tampilkan data train 
train.head()

# ukuran train
train.shape

# tampilkan nama seluruh kolom dalam train
train.columns

# deskripsi tentang train
train.describe()

# informasi tentang train
train.info()

"""### Count Plot dari data numerik"""

# kolom yang bertype data numerik
train_numeric = train.dtypes[train.dtypes != "object"].index
train_numeric

"""Catatan :
1. dalam kolom data train terdapat beberapa data numerik yang sebenarnya merupakan data katagorikal, seperti Pclass dan Survived.
2. kolom Survived nantinya akan dijadikan sebagai variabel terikat( target variabel)
3. variabel bebas (features variable) yang kasus ini yang bertype data numerik yaitu : Age, SibSp, Parch dan Fare
"""

# kolom bertype data numerik
train_numeric = train[['Age', 'SibSp', 'Parch', 'Fare']]

# count plot dari data numerik
for i in train_numeric.columns:
    plt.hist(train_numeric[i])
    plt.title(i)
    plt.show()

"""### Count Plot data kategorikal"""

# train bertype data kategorikal
train_categoric = train.dtypes[train.dtypes == "object"].index
train_categoric

"""Catatan :
karena terdapat beberapa data numerik yang sebenarnya merupakan data kategorik yang tidak terdapat didalam train_categorik, sehingga data tersebut akan dimasukan kedalam data kategorik
"""

# kolom yang bertype data katerorikal
train_categoric = train[['Sex', 'Ticket', 'Cabin', 'Embarked', 'Survived', 'Pclass']]

# barplot plot dari data kategorik
for i in train_categoric.columns:
    sns.barplot(train_categoric[i].value_counts().index,train_categoric[i].value_counts()).set_title(i)
    plt.show()

"""####Lihat korelasi antar variabel dalam train"""

# korelasi antar variabel train numerik
print(train_numeric.corr())

# korelasi antara variabel dependen Survived dengan variabel inependen yang bertype numerik 'Age', 'SibSp', 'Parch', 'Fare'
corr = (train[['Survived', 'Age', 'SibSp', 'Parch', 'Fare']]).corr().abs().unstack().sort_values(kind="quicksort", ascending=False).reset_index()
corr.rename(columns={"level_0": "Feature 1", "level_1": "Feature 2", 0: 'Correlation Coefficient'}, inplace=True)
corr[corr['Feature 1'] == 'Survived']

# korelasi antar variabel train katagorik
print(train_categoric.corr())

# korelasi antara variabel dependen Survived dengan variabel inependen yang bertype numerik 'Age', 'SibSp', 'Parch', 'Fare'
corr = (train[['Survived', 'Pclass']]).corr().abs().unstack().sort_values(kind="quicksort", ascending=False).reset_index()
corr.rename(columns={"level_0": "Feature 1", "level_1": "Feature 2", 0: 'Correlation Coefficient'}, inplace=True)
corr[corr['Feature 1'] == 'Survived']

"""#### Bandingkan nilai variabel dependen Survived dengan variabel independen numerikal dan kategorikal"""

# pivot tabel Survidev dengan train_numeric
pd.pivot_table(train, index = 'Survived', values = ['Age','SibSp','Parch','Fare'])

# pivot tabel Survidev dengan train_kategiric
pd.pivot_table(train, index = 'Survived', values = ['Pclass'])

"""Catatan :
karena 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Survived', bukan merupakan data angka sehingga nilai korelasi dan tabel pivotnya tidak dapat dimuat dengan menggunakan data berikut.
"""

# pivot tabel Survived dengan beberapa variabel kategorik
print(pd.pivot_table(train, index = 'Survived', columns = 'Sex', values = 'Ticket' ,aggfunc ='count'))
print()
print(pd.pivot_table(train, index = 'Survived', columns = 'Embarked', values = 'Ticket' ,aggfunc ='count'))
print()
print(pd.pivot_table(train, index = 'Survived', columns = 'Pclass', values = 'Ticket' ,aggfunc ='count'))

"""# DATA UNDERSTANDING TEST"""

# menampilkan data test
test.head()

# ukuran test
test.shape

# nama kolom yang terdapat dalam test
test.columns

# deskripsi tentang test
test.describe()

# info tentang test
test.info()

# kolom yang bertype data numerik
test_numeric = test.dtypes[test.dtypes != "object"].index
test_numeric

"""catatan :
di dalam data test terdapat data numerik yang sebenarnya merupakan data bertype katagorikal, sehingga data tersebut harus dimasukan kedalam data bertye katagorik yaitu Pclass
"""

# kolom bertype data numerik
test_numeric = test[['Age', 'SibSp', 'Parch', 'Fare']]

# count plot dari data numerik
for i in test_numeric.columns:
    plt.hist(test_numeric[i])
    plt.title(i)
    plt.show()

# test yang bertipe data kategorik
test_categoric = test.dtypes[test.dtypes == "object"].index
test_categoric

# kolom yang bertype data katerorikal
test_categoric = test[['Sex', 'Ticket', 'Cabin', 'Embarked', 'Pclass']]

# barplot plot dari data kategorik
for i in test_categoric.columns:
    sns.barplot(test_categoric[i].value_counts().index,test_categoric[i].value_counts()).set_title(i)
    plt.show()

# korelasi antar variabel test numerik
print(test_numeric.corr())

"""# HANDLING MISSING VALUE"""

# banyak baris train dan test
ntrain = train.shape[0]
ntest = test.shape[0]

# buat data baru
train_PassengerId = train["PassengerId"]
test_PassengerId = test["PassengerId"]
train_survived = train["Survived"]
y_train = train.Survived.values

# gabungkan train dan test
all_data = pd.concat((train, test)).reset_index(drop=True)

# hapus kolom Survived 
all_data.drop(['Survived', 'PassengerId'], axis=1, inplace=True)
all_data.head()

# cek ukuran data gabungan
all_data.shape

# descripsi tentang data gabungan
all_data.describe()

# info tentang data gabungan
all_data.info()

# feature numerik
data_categoric = all_data.dtypes[all_data.dtypes == "object"].index
data_categoric

# feature yang memiliki missing value
all_data.isnull().sum()[all_data.isnull().sum()>0]

# plot Age
sns.displot(all_data["Age"])

# isi missing value Age
all_data["Age"] = all_data["Age"].fillna(all_data["Age"].median())

# plot Fare
sns.displot(all_data['Fare'])

# isi missing value Fare
all_data["Fare"] = all_data["Fare"].fillna(all_data["Fare"].median())

# plot Embarked
sns.countplot(all_data['Embarked'])

# isi missing value Embarked
all_data['Embarked'] = all_data['Embarked'].fillna(all_data['Embarked'].mode()[0])

# plot Cabin
sns.countplot(all_data['Cabin'])

# isi missing value Cabin
all_data['Cabin'] = all_data['Cabin'].fillna(all_data['Cabin'].mode()[0])

# Recek missing value
all_data.isnull().sum()[all_data.isnull().sum()>0]

"""#### Feature angineering data gabungan"""

# buat feature baru cabin_aphabet
all_data['cabin_alphabet'] = all_data.Cabin.apply(lambda x: str(x)[0])
print(all_data.cabin_alphabet.value_counts())

# buat feature baru cabin_multiple 
all_data['cabin_multiple'] = all_data.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))
all_data['cabin_multiple'].value_counts()

# buat featur baru tiket ticket_numerik
all_data['ticket_numeric'] = all_data.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)
all_data['ticket_numeric'].value_counts()

"""### Convert Kategorikal feature"""

# convert Sex
all_data['Sex'] = all_data['Sex'].map( {'female': 1, 'male': 0} ).astype(int)

# conver Embarked
all_data['Embarked'] = all_data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)

# convert cabin_aplphabet
all_data['cabin_alphabet'] = all_data['cabin_alphabet'].map( {'A':1, 'B': 2, 'C':3, 'D':4, 'E': 5, 'F':6, 'G':7, 'T':8 } ).astype(int)

# recek 
all_data.head(5)

# hapus feature 'Name', 'Ticket', 'Cabin', 'family'
all_data = all_data.drop(['Name', 'Ticket', 'Cabin'], axis=1)

# recek feature yang telah dihapus
all_data.head(3)

"""### Split Data"""

# membagi all_data menjadi data train dan test
x_train = all_data[:ntrain]
x_test = all_data[ntrain:]
print(len(train))
print(len(test))

# cek ukuran x train
x_train.shape

# cek ukuran x test
x_test.shape

"""#MODELING"""

# import modul yang dibutuhkan  
from sklearn.model_selection import cross_val_score
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.ensemble import VotingClassifier

"""Terlebihdahulu lihat kinerja beberapa model berdasarkan parameter default. lihat kinerja model tersebut dengan menggunakan 5 cross validation (cv=5) untuk memperoleh baselinenya.

#### CROSS VALIDATION
"""

# metode Neive bayes (GaussNB)
gauss = GaussianNB()
cv = cross_val_score(gauss, x_train, y_train, cv=5)
print(cv)
print('rata-rata nilai cross validation metode Neive Bayyes : ',cv.mean())

# metode Regresi Logistik
logistic_reg =  LogisticRegression(max_iter = 2000)
cv = cross_val_score(logistic_reg, x_train, y_train, cv=5)
print(cv)
print('rata-rata nilai cross validation metode Regresi Logistik : ',cv.mean())

# metode Decision Tree
tree = tree.DecisionTreeClassifier(random_state = 1)
cv = cross_val_score(tree, x_train, y_train, cv=5)
print(cv)
print('rata-rata nilai cross validation metode Decision Tree : ',cv.mean())

# metode KNeigbors
knn =  KNeighborsClassifier()
cv = cross_val_score(knn, x_train, y_train, cv=5)
print(cv)
print('rata-rata nilai cross validation metode Kneigbors : ',cv.mean())

# metode Random Forest
forest =  RandomForestClassifier(random_state = 1)
cv = cross_val_score(forest, x_train, y_train, cv=5)
print(cv)
print('rata-rata nilai cross validation metode Random Forest : ',cv.mean())

# metode SVC
scv =  SVC(probability = True)
cv = cross_val_score(scv, x_train, y_train, cv=5)
print(cv)
print('rata-rata nilai cross validation metode SCV : ',cv.mean())

# metode XGBoost
xgb =  XGBClassifier(random_state =1)
cv = cross_val_score(xgb, x_train, y_train, cv=5)
print(cv)
print('rata-rata nilai cross validation metode XGBoost : ',cv.mean())

from sklearn.ensemble import VotingClassifier
# melakukan voting untuk mendapatkan vote populet dari berbagai metode
avg_voting = VotingClassifier(estimators = [('gauss', gauss),('logistic_reg', logistic_reg),
                                            ('knn', knn),('forest', forest),
                                            ('scv', scv), ('xgb', xgb)], voting = 'soft')

# Rata-rata score cross validation tiap metode
cv = cross_val_score(avg_voting, x_train, y_train, cv=5)
print(cv)
print('rata-rata nilai cross validation menggunakan voting : ',cv.mean())

# import modul yang diperlukan
from sklearn.model_selection import GridSearchCV 
from sklearn.model_selection import RandomizedSearchCV

"""### Tone model untuk meningkatkan perfoma model """

# fungsi peningkatan model
def clf_performance(classifier, model_name):
    print(model_name)
    print("__________________________________________________________________________________")
    print('Best Score: ' + str(classifier.best_score_))
    print('Best Parameters: ' + str(classifier.best_params_))
    print("__________________________________________________________________________________")

# Tone model Regresi Logistic
lr = LogisticRegression()
param_grid = {'max_iter' : [2000],
              'penalty' : ['l1', 'l2'],
              'C' : np.logspace(-4, 4, 20),
              'solver' : ['liblinear']}

clf_lr = GridSearchCV(lr, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)
best_clf_lr = clf_lr.fit(x_train,y_train)
clf_performance(best_clf_lr,'Logistic Regression')

# Tone model Kneihbors
knn = KNeighborsClassifier()
param_grid = {'n_neighbors' : [3,5,7,9],
              'weights' : ['uniform', 'distance'],
              'algorithm' : ['auto', 'ball_tree','kd_tree'],
              'p' : [1,2]}
clf_knn = GridSearchCV(knn, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)
best_clf_knn = clf_knn.fit(x_train,y_train)
clf_performance(best_clf_knn,'KNN')

"""### Model fix"""

# pilih model regresi logistik
best_clf_lr.fit(x_train, y_train)
y_hat_lr = best_clf_lr.predict(x_test).astype(int)

# buat dataframe baru submission
final_data = {'PassengerId': test.PassengerId, 'Survived': y_hat_lr}
submission = pd.DataFrame(data=final_data)

# simpan submission
submission.to_csv('submission_lr.csv', index =False)
submission











